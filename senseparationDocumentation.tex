\documentclass[conference]{acmsiggraph}

	
\usepackage{ulem}  % unterstreichen, durchstreichen, etc. von Text
\usepackage{amssymb} % Symbole, z.B. Checkmark
\usepackage{cleveref}
\usepackage{tabularx}
\usepackage{array}
\usepackage[T1]{fontenc}
\usepackage{table_extensions}

\DeclareGraphicsExtensions{.pdf,.jpg,.pdf,.mps,.png}
\graphicspath{{images/}} 

\newcommand{\todo}[1]{\textcolor{red}{TODO: #1}}


\title{Senseparation: Design and Implementation of the Cave Application and the Network Communication}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% authors
%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\author{
	Felix Manke\thanks{e-mail: felix.manke@campus.lmu.de}\\LMU Munich
	\and
	Tibor Goldschwendt\thanks{e-mail: goldschwendt@cip.ifi.lmu.de}\\LMU Munich
	\and
	Oleg Maltsev\thanks{e-mail: ga49bof@mytum.de}\\TU Munich
}
	
\pdfauthor{Felix Manke, Tibor Goldschwendt}

\keywords{radiosity, global illumination, constant time}

\begin{document}

%% \teaser{
%%   \includegraphics[height=1.5in]{images/sampleteaser}
%%   \caption{Spring Training 2009, Peoria, AZ.}
%% }

\maketitle


%%%%%%%%%%%%
% ABSTRACT %
%%%%%%%%%%%%

\begin{abstract}
The interdisciplinary and experimental project 'Senseparation' focuses on the cross-border networking of people between virtual and real space.
An encounter takes place between two people at different locations, one being an empty, dark room and the other one being an virtual world.
Tactile, visual, and auditory perception are separated and partially blocked for each user, therefore amplifying the remaining senses in order to initiate an unfamiliar and novel kind of encounter.
By means of an avatar, the user in virtual reality is able to interact with the person in
the real space. Emotionless and distant encounters on a virtual level are experienced in a new way.
\end{abstract}

\copyrightspace




%%%%%%%%%%%%%%%%
% INTRODUCTION %
%%%%%%%%%%%%%%%%

\section{Introduction}
Intense effort is made in the field of Human Computer Interaction (HCI), looking for possibilities to make the communication with digital data more human and intuitive.
Based on this idea 'Senseparation' was developed: a concept of a telehaptic encounter between two persons in distant places. With 'Senseparation' we decided to go beyond existing projects \ref{???}, 
%
% TODO: Referenz zu: Stahl Stenslie, Tony Olsson, Andreas Goransson, and David Cuartielles. Stitchies: Towards Telehaptic Performativity. In Proceedings of the 8th International Conference on Tangible, Embedded and Embodied Interaction, TEI '14, pages 327{329, New York, NY, USA, 2013. ACM.
%
mainly focusing on touch and added pictorial visualization and sound. This takes up the well-known habits of an real-life encounter.

As an interdisciplinary and intercity collaborative project, Senseparation intends to discover transpositional sensorial experiences, specificly the cross-border networking of people between virtual and real space.
An encounter takes place between two people in different locations: one being inside a CAVE-like institution and exposed to a virtual world that he/she can navigate through and interact with, the other one being in a dark room stripped off any visual stimulation, and being left only with the sounds made by an audio system and distinct haptic feedback coming from a jacket with vibration motors spread on it that he/she is wearing on his/her body.\\
By this means, tactile, visual, and auditory sensory perceptions are separated between both locations. By this, we hope to amplify the remaining stimuli and create a new, novel way of encounter.

To make communication between both individuals possible, some exchange of information across geographic boundaries is necessary. Therefore data about both users is gathered within the dark room as well as within the CAVE and send over to the other location via network.


\todo{umschreiben: \textit{Multilayer of behaviors in virtual CAVE stimulate the layer of sensation in the dark room correspondingly by mapping the behaviorial infomation onto the feedback suite. Simultaneously the sound system is also modified according to the encounter. By this means of an avatar, the user in virtual reality is able to interact with the person in the real space.}}

Senseparation is a collaborative project between the University of Arts and Industrial Design Linz, Ludwig Maximilian University of Munich and Leibniz Supercomputing Centre. More than 30 people from different fields worked on realizing the whole project.\\
Starting in September 2013, several workshops and presence meetings in Munich and Linz as well as numerous remote-calls guided the individual teams through the process of creating this project.
Different ideas and concepts finally lead into the final concept of separating senses during a distant encounter. With 'Senseparation', arts and technology merge - combining the best of both worlds and creating an novel, immersive installation.


\begin{itemize}
\item motivation
\item{
	general description of the project
	\begin{itemize}
	\item what is it\\
	 ($\rightarrow$ introductory text from wiki... separation of senses, visual, tactile, ...)
	\item dark room side (explanation of dark room: what happens there, what does the user do. Not too technical\\
	 $\Rightarrow$ only the concept)
	\item communication
	(point out, that data gets transmitted over to the cave so that there is a spatial separation as well)
	\item CAVE-side\\
	(how does the interaction in the cave look like? what happens there? How does the room-user affect the cave-environment and vice versa...)
	\end{itemize}
}
\item entire team\\
	  (describe, who worked on the project... what about a complete list of all names in the appendix maybe, like credits in a movie or video game?)
\item aspects: arts vs. technology\\
		(combination of both worlds, merging the best aspects, creating an immersive installation)
\item how we find the concept\\
		(description of the development process $\Rightarrow$ time (October till March... still ongoing to prepare it for future exhibitions...), presence meetings in Munich and Linz aka. Workshops, several Skype-Meetings, different approaches and ideas (interactive table, visualising time, ... , finally: separation of senses) 
\item purpose of this paper
\end{itemize}

\section{Implementation}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPLICATION ARCHITECTURE %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The overall system architecture is depicted in \cref{FIG:SYSTEM_ARCHITECTURE} and consists of three main modules: The \textit{dark room} (with the haptic vest and the audio system), the \textit{VR-application} running in the CAVE and the \textit{network connection} the room and the CAVE.

\begin{figure}[ht]
	\includegraphics[width=\linewidth]{images/system_architecture.png}
	\caption{\todo{remake}}
	\label{FIG:SYSTEM_ARCHITECTURE}
\end{figure}

The dark room is equipped with a Microsoft Kinect\footnote{TODO: Referenz / kurze Beschreibung Kinect} for tracking the user's position and movement, and a sound system capable of producing spatial 3D-sound. The person within the dark room is wearing a vest that has several (TODO: how many exactly?) vibration motors built into it. These motors are placed at distinct locations like the shoulders, the neck, the back and the arms and provide haptic feedback to the person, wearing the vest. They are controlled individually by an Arduino Mini\footnote{TODO: Link/Beschreibung zum Arduino Mini} board, that is connected to a computer via Bluetooth.\par
Also, there is a compass built into the vest that is used to determine the user's rotation. Together with the data gathered by the Kinect, we can determine the position and rotation of the person wearing the vest within the dark room.\par
This information gets send over to the CAVE-application via network and gets directly mapped onto the movement of an avatar in the virtual world. The user in the CAVE can thereby see the movements of the person in the dark room as the avatar moves around and rotates accordingly. Further, he/she can interact with the avatar by touching it, hitting it, or walking through it. We distinguish these three different types of interaction and call them 'touch', 'hit', and 'bump'.\par
The CAVE is also equipped with an IR tracking system which allows us to determine the exact position and rotation of the person inside of it.\par
Information about the events of interaction (touch, hit, bump) as well as the additional data about the movements of the user within the CAVE are send back over the network to the dark room. There they are translated into tactile feedback coming from the vibration motors built into the haptic vest and into spatial sound being produced by the sound system.
This way, the person in the dark room can hear the movements of the person in the CAVE and feel the interactions (touch/hit/bump) right on their own body.\par

In the following sections we are going to describe all the components and the software that drive the CAVE application and the network communication to the dark room. We are not going to describe the setup and software of the dark room itself in more detail. For more information about the dark room implementation see \ref{?? TODO: Referenz zu einer Beschreibung der DarkRoom Implementierung}

\begin{figure}[ht]
	\textit{Graphic of the CAVE-side application}
	\caption{\todo{make}}
	\label{FIG:CAVE_APP_ARCHITECTURE}
\end{figure}

The general architecture of the CAVE-side implementation of Senseparation consists of a network, tracking, rendering and a core module as depictured in \cref{FIG:CAVE_APP_ARCHITECTURE}.\par

\paragraph{Core Module}
The core module stores all information either predefined (e.g. the virtual world), retrieved from the Dark Room or entered by means of CAVE user interaction. On the basis of this information the core module calculates the current appearance of the avatar and initiates the transmission of the CAVE user's current position and certain interaction events such as touches. All parts of the core module's realisation related to the visualisations inside the CAVE and the avatar are described in \cref{SEC:VISUALISATION}. The parts specific to one of the other modules are explained in the \cref{SEC:NETWORK} or \ref{SEC:INTERACTION}.

\paragraph{Network Module}
The network module is responsible for exchanging all relevant information between the the CAVE application and Senseparation's the Dark Room-side implementation. To realise this a Senseparation protocol must be defined on application level and integrated into the CAVE application. Detailed information are given in \cref{SEC:NETWORK}.

\paragraph{Tracking Module} 
This module processes the tracking data, which is collected by the tracking devices such as the Wand or the head tracking, and transfers the information to the core module. The tracking data servers as the foundation to enable interaction between the CAVE user and the person in the Dark Room. See \cref{SEC:INTERACTION} for further information.

\paragraph{Rendering Module}
The rendering module displays the virtual world kept by the core module in the CAVE.... \todo{finish}

%%%%%%%%%%%
% NETWORK %
%%%%%%%%%%%

\subsection{Network}
\label{SEC:NETWORK}

\todo{replace: The CAVE application uses two threads: one rendering thread -- that also processes tracking information and calculates the avatar -- and thread for data reception from the Dark Room. Since the information received over the network must be shared with the rendering module we must synchronize the local data of both the threads.}

\begin{itemize}
\item introduction
\item{
	purpose of this module
	\begin{itemize}
		\item real time synchronisation of certain avatar parameters and the real person in the room
		\item synchronisation of the noetworking and rendering thread
	\end{itemize}
}
\item{
	evolution over time
	\begin{itemize}
		\item first idea: use the cdpp \cite{goldschwendt13collaborative}
		\item{
			Advantages:
			\begin{itemize}
				\item easily extendable
				\item experience in using it
				\item fast and realiable
				\item manages update cycles, takes care of overloading etc.
				\item good configuration (e.g. sockets)
			\end{itemize}
		}
		\item{
			Disadvantages:
			\begin{itemize}
				\item C++ only
				\item focuses on dynamic virtual worlds (creation and deletion of objects)
			\end{itemize}
		}
		\item {
			\item{
				second idea: use the OSC
				\begin{itemize}
					\item{
						Advantages:
						\begin{itemize}
							\item event oriented
							\item support for many programming languages
							\item more stable
							\item more lightweight
							\item also fast and reliable
						\end{itemize}
					}
					\item{
						Disadvantages:
						\begin{itemize}
							\item Libraries does not provide the configuration possibilities we needed
						\end{itemize}
					}
				\end{itemize}
			}
		}
	\end{itemize}
}
\item{
	used technologies
	\begin{itemize}
	\item{
		OSC
		\begin{itemize}
			\item{
				general:
				\begin{itemize}
					\item developed by Wright and Freed in 1997 \cite{Wright97Open}
					\item intended for interactive real time music transmission
					\item bit based protocol -> transmittable over arbitrary protocols like IP, TCP, UDP
					\item should be open in the sense that there only few requirements in the implementations
					\item therefore diverse realisations available
					\item due to the open nature other applications possible -> our project (no real sound mapping) \cite{Wright05Open}
				\end{itemize}
			}
			\item{
				specification \cite{Wright02Open}
				\begin{itemize}
					\item osc packages consist of osc messages or bundles
					\item bundles include a timetag and other bundles recursively or messages
					\item messages consist of address patterns, type string and arguments
					\item Messages get dispatched to specific methods
				\end{itemize}
			}
		\end{itemize}
	}
	\item{
		Liblo
		\begin{itemize}
			\item implementation of osc in the programming language c \cite{Harris07liblo}
			\item lightweight
			\item offers two sets of api: low level, high level
			\item high-level: creation of addresses and sending of messages
			\item low-level: creation of servers, methods for sending messages with more options, thread control etc.
			\item why do we use it?
			\item{
				Advantages
				\begin{itemize}
					\item lightweight
					\item C -> well integrates with our project
				\end{itemize}
			}
			\item{
				Disadvantages
				\begin{itemize}
					\item Handles sockets etc. by itself
					\item Not so many methods for configuration
				\end{itemize}
			}
		\end{itemize}
	}
	\end{itemize}
}
\item{
	steps of the implementation
	\begin{itemize}
		\item define protocol on application level (\cref{TAB:PROTOCOL_DARK_ROOM_CAVE}, \cref{TAB:PROTOCOL_CAVE_DARK_ROOM})
		\item enhance cave app with support for our protocol
		\item apply and send changes
		\item patching of liblo
	\end{itemize}
}
%\item{
%	detailed description
%	\begin{itemize}
%	\item UML
%	\item programming language, libraries...
%	\item API
%	\item implementation, code examples, algorithms,...
%	\end{itemize}
%}
\end{itemize}

\begin{table*}[ht]
	
	\begin{minipage}{\linewidth}
		\begin{tabularx}{\linewidth}{| +>{\itshape}L L L L L L L >{\ttfamily}L L | L}
			\hline
			\rowstyle{\bfseries\upshape\rmfamily}
			Description         & Data Type     & Range                       & Origin                      & Coordinate System        & Units                & OSC Type Tags\footnote{\url{http://opensoundcontrol.org/spec-1_0}} & URL & Base Protocol \\ 
			\hline
			\hline
			Activity Idicator   & nominal       & 0 (end),\newline1 (begin)   &                             &                          &                      & i     & /cave{\textunderscore}person/activity   & TCP \\ 
			\hline
			Position            & real vector   & unbounded                   & center of DARK ROOM floor   & right-handed Cartesian   & centimeters          & ff    & /cave{\textunderscore}person/position   & UDP \\ 
			\hline
			 Velocity           & real          & [0, 1]                      &                             &                          &                      & f     & /cave{\textunderscore}person/velocity   & UDP\\ 
			\hline
			 Touch Start/End    & nominal       &                             &                             & ---                      & 0 (end), 1 (begin)   & i     & /cave{\textunderscore}person/touch      & TCP \\ 
			\hline
			 Touch              & real vector   &                             &                             &                          &                      & fff   & /cave{\textunderscore}person/touching   & UDP \\ 
			\hline
			 Hit                & real vector   &                             &                             &                          &                      & fff   & /cave{\textunderscore}person/hit        & TCP \\ 
			\hline
			 Bumb               & real vector   &                             &                             &                          &                      & ff    & /cave{\textunderscore}person/bump       & TCP \\ 
			\hline
		\end{tabularx}
	\end{minipage}
	\caption{Protocol definition for packages sent from DarkRoomServer to CAVE}
	\label{TAB:PROTOCOL_DARK_ROOM_CAVE}
\end{table*}

\begin{table*}[ht]
	\begin{minipage}{\linewidth}
		\begin{tabularx}{\linewidth}{| +>{\itshape}L L L L L L L >{\ttfamily}L >{\ttfamily}L | L}
			\hline
			\rowstyle{\bfseries\upshape\rmfamily}
			Description         & Data Type     & Range                       & Origin                      & Coordinate System        & Units                & OSC Type Tags\footnote{\url{http://opensoundcontrol.org/spec-1_0}} & URL & Base Protocol \\ 
			\hline
			\hline
			Position            & real vector   & unbounded                   & center of DARK ROOM floor   & right-handed Cartesian   & centimeters          & ff    & /room{\textunderscore}person/position      & UDP \\ 
			\hline
			Orientation         & real          & $ [0, 2\pi] $               &                             &                          & Radians              & f     & /room{\textunderscore}person/orientation   & UDP\\ 
			\hline
		\end{tabularx}
	\end{minipage}
	\caption{Protocol definition for packages sent from CAVE to DarkRoomServer}
	\label{TAB:PROTOCOL_CAVE_DARK_ROOM}
\end{table*}



%%%%%%%%%%%%%%%%%
% VISUALISATION %
%%%%%%%%%%%%%%%%%

\subsection{Visualisation}
The virtual world with the Avatar as a representation of the remote room-user is displayed in stereoscopic 3D within the 5-sided projection installation at the Virtual Reality and Visualisation Centre (V2C) a the Leibniz Supercomputing Centre.\\
The basic idea of the 5-sided projection installation is based on the concept of the 'CAVE' (CAVE Automatic Virtual Environment) by Carolina Cruz-Neira \cite{Cruz-Neira92} and puts the user directly and physically into an virtual world.\\
This is achieved by the user entering a 2.7 x 2.7 x 2.7 meters sized cube \textit{(see figure \ref{fig:5sided})}, whose walls, floor, and ceiling are being projected with computer-rendered images and totally cover the user's field of view.

\begin{figure}[htb]
  \centering
  \includegraphics[width=2.0in]{5_sided_cave}
  \caption[The 5-sided projection installation, source: \newline\href{http://www.lrz.de/services/v2c\_ de/bilder/5sided.jpg}{http://www.lrz.de/services/v2c\_de/bilder/5sided.jpg}]{\textit{The 5-sided projection installation of the V2C at the LRZ}}
  \label{fig:5sided}
\end{figure}

As the sides of the CAVE are each being illuminated by two HD stereo projectors, the user - wearing 3D-shutter glasses - is able to experience the virtual scene in full, active stereoscopic vision.\\
An integrated infrared tracking system measures the position of the user's head inside of the CAVE and allows for adapting the camera perspective of the 3D scene to match the user's point of view.\\
By combining all this features the user finally feels like he would actually be physically present in the virtual world.\\
Being able to create this strong feeling of presence and immersion allows to provide a unique, fascinating presentation of an interactive, virtual 3D-environment.

To create this virtual environment, the CAVE-apllication uses OpenSG\footnote{for more information on OpenSG see \href{http://www.opensg.org/}{www.opensg.org}}, which is a portable scenegraph system that allows to create realtime graphics programs and is very well suited for virtual reality applications. As OpenSG is Open Source (LGPL\footnote{for more information on the GNU Lesser General Public License (LGPL) see \href{https://www.gnu.org/licenses/lgpl.html}{www.gnu.org/licenses/lgpl.html}}) it can be used freely. OpenSG runs on Windows, Linux, Solaris and MacOS X and is based on OpenGL.

The decision on using OpenSG was made based on the operating-system independence, the free license and the orientation towards virtual reality applications. \todo{something else???}

\label{SEC:VISUALISATION}

\begin{itemize}
\item introduction
\item{used technologies
	\begin{itemize}
	\item{CAVE
		\begin{itemize}
		\item \sout{some technical details on the cave} \checkmark 
		\item \sout{ideally some pictures/figures...} \checkmark
		\end{itemize}
	}
	\item{OpenSG
		\begin{itemize}
		\item{ What is OpenSG?
			\begin{itemize}
			\item \sout{rough description}\checkmark
			\item why do we use it?
			\item \sout{some references (OpenSG, docu, etc ...)} \checkmark
			\end{itemize}
		}
		\item{The Scenegraph
			\begin{itemize}
			\item figure / diagram
			\item description of all nodes
			\item reasons for this layout of the scenegraph
			\end{itemize}
		}
		\end{itemize}
	}
	\item{GLUT
		\begin{itemize}
		\item{What is the OpenGL Utility Toolkit?
			\begin{itemize}
			\item rough description
			\item some references
			\end{itemize}
		}
		\item{What is it used for?
			\begin{itemize}
			\item basic GLUT window to create program/update loop
			\item receive mouse and keyboard input
			\item ...?
			\end{itemize}
		}
		\item How is it implemented?
		\end{itemize}
	}
	\item{CaveSceneManager
		\begin{itemize}
		\item What is the CaveSceneManager?
		\item some references
		\item why do we use it / what do we need it for?
		\item how did we implement it?
		\end{itemize}
	}
	\item don't forget to mention the 3D-models coming from the artists, build in 3D-Max and Maya, I guess...
	\end{itemize}
}
\item{The Avatar
	\begin{itemize}
	\item{Introduction
		\begin{itemize}
		\item{What is an Avatar?
			\begin{itemize}
			\item some background information on the concept of avatars
			\item including some references
			\end{itemize}
		}
		\item{Why do we need it / What do we use it for?
			\begin{itemize}
			\item visualizing the remote user and his movement through space
			\item allowing for interaction with the remote user via this virtual representaion
			\end{itemize}
		}
		\end{itemize}			
	}
	\item{Design of the Avatar
		\begin{itemize}
		\item what functionality was needed
		\item how should the avatar behave
		\item{what should it look like?
			\begin{itemize}
			\item human-like representation
			\item but still abstract, artificial
			\end{itemize}
		}
		\item{what should the interaction with the avatar look like?
			\begin{itemize}
			\item approaching, touching, hitting,...
			\item interaction through movement in space
			\end{itemize}
		}
		\item{what implications came from this for the implementation of the avatar?
			\begin{itemize}
			\item needed to look human-like
			\item needed to be able to react visually to interaction
			\item on the one hand "large scale proximity" $\Rightarrow$ the user moving towards/away from the avatar
			\item on the other hand "small scale proximity" $\Rightarrow$ the user touching different parts of the avatar
			\end{itemize}
		}
		\end{itemize}			
	}
	\item{Implementation
		\begin{itemize}
		\item UML
		\item{visuals
			\begin{itemize}
			\item human shape / silhouette
			\item rotating cubes / orbits
			\item exchange of cubes with the ground
			\item vest
			\item varying size depending on distance between user and avatar
			\end{itemize}
		}
		\item{interaction
			\begin{itemize}
			\item interaction by proximity
			\item changing size (far away $\Rightarrow$ diffuse large cube cloud; close $\Rightarrow$ defined human shape, plus: vest becomes visible)
			\item pulsating cubes(touch, hit, bump)
			\end{itemize}
		}
		\item components/variables/methods
		\item description of all subclasses
		\item usage / API
		\item{network
			\item what gets send over the network?
			\item what gets received?
			\item ... where to put this in the doc? maybe here just a reference to the network chapter?
		}
		\end{itemize}		
	}
	\end{itemize}
}
\item{The Virtual World
	\begin{itemize}
	\item visuals
		\begin{itemize}
		\item some details on size, purpose, etc. ...
		\item screenshots
		\end{itemize}
	\item creation process
		\begin{itemize}
		\item built in 3DMax / Maya / Blender
		\item import into OpenSG $\Rightarrow$ plus code snippet
		\end{itemize}
	\item movement /navigation
		\begin{itemize}
		\item Wand to lead direction
		\item Joystick to move around
		\item tracking of wand to move the user's hand around for interaction (touching, hitting,...)
		\end{itemize}
	\item movement constraints
		\begin{itemize}
		\item maximum speed
		\item borders for navigation
		\end{itemize}
	\end{itemize}
}
\item (evolution over time ?)
\item{
	detailed description
	\begin{itemize}
	\item UML, Code
	\item programming language, libraries...
	\item API
	\item implementation, code examples, algorithms,...
	\end{itemize}
}
\end{itemize}





%%%%%%%%%%%%%%%
% INTERACTION %
%%%%%%%%%%%%%%%

\subsection{Tracking and Interaction}
\label{SEC:INTERACTION}

\begin{itemize}
\item introduction
\item{ used technologies
	\begin{itemize}
	\item{IR tracking system
		\begin{itemize}
		\item{description of the technical Cave-Setup for Headtracking
			\begin{itemize}
			\item infrared lights
			\item cameras
			\item figure / blueprint of tracking setup in cave
			\item markers on 3D-glasses (picture of 3D-shutterglasses with markers on it)
			\item markers on Wand
			\end{itemize}
		}
		\item{what can be achieved by this?
			\begin{itemize}
				\item Headtracking $\Rightarrow$ correct perspective
				\item Tracking of Wand position $\Rightarrow$ position of user's hand
				\item immersion
				\item interaction
				\item ...?
			\end{itemize}		
		}
		\end{itemize}
	}
	\item{Wand
		\begin{itemize}
		\item short description of the Wand and its features
		\item figure / picture of the Wand
		\item references (manufacturer / documentation)
		\end{itemize}
	}
	\item{VRPN
		\begin{itemize}
		\item short description of the framework/library
		\item references
		\item what do we use it for?
		\item how is it implemented?
		\end{itemize}
	}
	\end{itemize}
}
\item evolution over time
\item{
	detailed description
	\begin{itemize}
	\item UML
	\item programming language, libraries...
	\item API
	\item implementation, code examples, algorithms,...
	\end{itemize}
}
\end{itemize}

\section{Conclusion \& Further Extensions}



%%%%%%%%%%%%%%%%%%%%%%%
% FORMATTING EXAMPLES %
%%%%%%%%%%%%%%%%%%%%%%%


\textit{\textbf{Formatting examples (will be deleted later on...)}}

\cref{SEC:CFE}\\
\Cref{SEC:CFE}

(\textit{see \cref{FIG:SAMPLE}})

\label{SEC:CFE}

\begin{equation}
 \sum_{j=1}^{z} j = \frac{z(z+1)}{2}
\end{equation}

\begin{eqnarray}
x & \ll & y_{1} + \cdots + y_{n} \\
  & \leq & z
\end{eqnarray}

\begin{figure}[ht]
  \centering
  \includegraphics[width=1.5in]{images/samplefigure}
  \caption{Sample illustration.}
  \label{FIG:SAMPLE}
\end{figure}

\section*{Acknowledgements}

To my mum, my dad, and the dog. 

\bibliographystyle{acmsiggraph}
\bibliography{senseparationDocumentation}
\end{document}
